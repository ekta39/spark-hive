{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5039f0e4-9088-4ac3-999b-7ae07f13c0c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Using PySpark to Handle Hive Query\n",
    "\n",
    "# 1. Import the pyspark and pyspark SQL modules and also specify the app name \n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "appName= \"hive_pyspark\"\n",
    "master= \"local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caadfba7-ae92-4c87-9f25-da98ef795da7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n||\n++\n++\n\n+-------------------------+------------------------------------------+\n|database_description_item|database_description_value                |\n+-------------------------+------------------------------------------+\n|Catalog Name             |spark_catalog                             |\n|Namespace Name           |spark_example                             |\n|Comment                  |                                          |\n|Location                 |dbfs:/user/hive/warehouse/spark_example.db|\n|Owner                    |root                                      |\n+-------------------------+------------------------------------------+\n\n++\n||\n++\n++\n\n"
     ]
    }
   ],
   "source": [
    "# 2. Create a spark session and enable the Hive support to interact with the hive database\n",
    "spark = SparkSession.builder \\\n",
    "\t.master(master).appName(appName).enableHiveSupport().getOrCreate() \n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS spark_example\").show()\n",
    "spark.sql(\"DESCRIBE DATABASE spark_example\").show(truncate=False)\n",
    "spark.sql(\"USE spark_example\").show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2057175a-1f2c-494b-b08e-09adb23608d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n| databaseName|\n+-------------+\n|      default|\n|spark_example|\n+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "#3. Verify the databases in hive using pyspark\n",
    "df=spark.sql(\"show databases\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "760d090e-2b2f-4122-964f-d341fc2306de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+----+---------------+-------------------+-----------+--------------------+----------------------+---------------+--------------------+-----------+-----------+----------+---------+-------------------------+-----------------+----+-------+-------+----+----+----+----+--------------+\n|Employee_ID|Gender| Age|Education_Level|Relationship_Status|   Hometown|                Unit|Decision_skill_possess|Time_of_service|Time_since_promotion|growth_rate|Travel_Rate|Post_Level|Pay_Scale|Compensation_and_Benefits|Work_Life_balance|VAR1|   VAR2|   VAR3|VAR4|VAR5|VAR6|VAR7|Attrition_rate|\n+-----------+------+----+---------------+-------------------+-----------+--------------------+----------------------+---------------+--------------------+-----------+-----------+----------+---------+-------------------------+-----------------+----+-------+-------+----+----+----+----+--------------+\n|  EID_23371|     F|42.0|              4|            Married|   Franklin|                  IT|            Conceptual|            4.0|                   4|         33|          1|         1|      7.0|                    type2|              3.0|   4| 0.7516| 1.8688| 2.0|   4|   5|   3|        0.1841|\n|  EID_18000|     M|24.0|              3|             Single|Springfield|           Logistics|            Analytical|            5.0|                   4|         36|          0|         3|      6.0|                    type2|              4.0|   3|-0.9612|-0.4537| 2.0|   3|   5|   3|         0.067|\n|   EID_3891|     F|58.0|              3|            Married|    Clinton|             Quality|            Conceptual|           27.0|                   3|         51|          0|         2|      8.0|                    type2|              1.0|   4|-0.9612|-0.4537| 3.0|   3|   8|   3|        0.0851|\n|  EID_17492|     F|26.0|              3|             Single|    Lebanon|Human Resource Ma...|            Behavioral|            4.0|                   3|         56|          1|         3|      8.0|                    type2|              1.0|   3|-1.8176|-0.4537|null|   3|   7|   3|        0.0668|\n|  EID_22534|     F|31.0|              1|            Married|Springfield|           Logistics|            Conceptual|            5.0|                   4|         62|          1|         3|      2.0|                    type3|              3.0|   1| 0.7516|-0.4537| 2.0|   2|   8|   2|        0.1827|\n+-----------+------+----+---------------+-------------------+-----------+--------------------+----------------------+---------------+--------------------+-----------+-----------+----------+---------+-------------------------+-----------------+----+-------+-------+----+----+----+----+--------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# 4. Read the CSV file from the local write to the table in hive using pyspark \n",
    "#datafile = spark.read.csv(\"dbfs:/FileStore/shared_uploads/pawansharma2045@gmail.com/Train.csv\",header=True)\n",
    "datafile = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"dbfs:/FileStore/shared_uploads/pawansharma2045@gmail.com/Train.csv\")\n",
    "datafile.show(5)\n",
    "datafile.write.saveAsTable(\"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bb69cc3-d9c4-4842-b206-af95168c75e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+----+---------------+-------------------+-----------+--------------------+----------------------+---------------+--------------------+-----------+-----------+----------+---------+-------------------------+-----------------+----+-------+-------+----+----+----+----+--------------+\n|Employee_ID|Gender| Age|Education_Level|Relationship_Status|   Hometown|                Unit|Decision_skill_possess|Time_of_service|Time_since_promotion|growth_rate|Travel_Rate|Post_Level|Pay_Scale|Compensation_and_Benefits|Work_Life_balance|VAR1|   VAR2|   VAR3|VAR4|VAR5|VAR6|VAR7|Attrition_rate|\n+-----------+------+----+---------------+-------------------+-----------+--------------------+----------------------+---------------+--------------------+-----------+-----------+----------+---------+-------------------------+-----------------+----+-------+-------+----+----+----+----+--------------+\n|  EID_23371|     F|42.0|              4|            Married|   Franklin|                  IT|            Conceptual|            4.0|                   4|         33|          1|         1|      7.0|                    type2|              3.0|   4| 0.7516| 1.8688| 2.0|   4|   5|   3|        0.1841|\n|  EID_18000|     M|24.0|              3|             Single|Springfield|           Logistics|            Analytical|            5.0|                   4|         36|          0|         3|      6.0|                    type2|              4.0|   3|-0.9612|-0.4537| 2.0|   3|   5|   3|         0.067|\n|   EID_3891|     F|58.0|              3|            Married|    Clinton|             Quality|            Conceptual|           27.0|                   3|         51|          0|         2|      8.0|                    type2|              1.0|   4|-0.9612|-0.4537| 3.0|   3|   8|   3|        0.0851|\n|  EID_17492|     F|26.0|              3|             Single|    Lebanon|Human Resource Ma...|            Behavioral|            4.0|                   3|         56|          1|         3|      8.0|                    type2|              1.0|   3|-1.8176|-0.4537|null|   3|   7|   3|        0.0668|\n|  EID_22534|     F|31.0|              1|            Married|Springfield|           Logistics|            Conceptual|            5.0|                   4|         62|          1|         3|      2.0|                    type3|              3.0|   1| 0.7516|-0.4537| 2.0|   2|   8|   2|        0.1827|\n+-----------+------+----+---------------+-------------------+-----------+--------------------+----------------------+---------------+--------------------+-----------+-----------+----------+---------+-------------------------+-----------------+----+-------+-------+----+----+----+----+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 5. Fetch rows from the table in hive using pyspark and store them in the dataframe\n",
    "df=spark.sql(\"select * from Train limit 5\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91c3fd92-6997-4dbe-aa3f-14acddaa7e44",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+---------+-------+\n|col_name                 |data_type|comment|\n+-------------------------+---------+-------+\n|Employee_ID              |string   |null   |\n|Gender                   |string   |null   |\n|Age                      |string   |null   |\n|Education_Level          |string   |null   |\n|Relationship_Status      |string   |null   |\n|Hometown                 |string   |null   |\n|Unit                     |string   |null   |\n|Decision_skill_possess   |string   |null   |\n|Time_of_service          |string   |null   |\n|Time_since_promotion     |string   |null   |\n|growth_rate              |string   |null   |\n|Travel_Rate              |string   |null   |\n|Post_Level               |string   |null   |\n|Pay_Scale                |string   |null   |\n|Compensation_and_Benefits|string   |null   |\n|Work_Life_balance        |string   |null   |\n|VAR1                     |string   |null   |\n|VAR2                     |string   |null   |\n|VAR3                     |string   |null   |\n|VAR4                     |string   |null   |\n+-------------------------+---------+-------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE FORMATTED Train\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7dac224-3714-4a98-93b5-2bbf865c5e96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Employee_ID: string (nullable = true)\n |-- Gender: string (nullable = true)\n |-- Age: string (nullable = true)\n |-- Education_Level: string (nullable = true)\n |-- Relationship_Status: string (nullable = true)\n |-- Hometown: string (nullable = true)\n |-- Unit: string (nullable = true)\n |-- Decision_skill_possess: string (nullable = true)\n |-- Time_of_service: string (nullable = true)\n |-- Time_since_promotion: string (nullable = true)\n |-- growth_rate: string (nullable = true)\n |-- Travel_Rate: string (nullable = true)\n |-- Post_Level: string (nullable = true)\n |-- Pay_Scale: string (nullable = true)\n |-- Compensation_and_Benefits: string (nullable = true)\n |-- Work_Life_balance: string (nullable = true)\n |-- VAR1: string (nullable = true)\n |-- VAR2: string (nullable = true)\n |-- VAR3: string (nullable = true)\n |-- VAR4: string (nullable = true)\n |-- VAR5: string (nullable = true)\n |-- VAR6: string (nullable = true)\n |-- VAR7: string (nullable = true)\n |-- Attrition_rate: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# 6. Print the schema of the table in hive using pyspark\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "252b6e3b-a335-44a2-9bd7-899a3a99775a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Read and Load DATA into Employee table \n",
    "\n",
    "df1 = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"dbfs:/FileStore/shared_uploads/pawansharma2045@gmail.com/employees.csv\")\n",
    "df1.write.saveAsTable(\"Employees\")\n",
    "\n",
    "df2 = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"dbfs:/FileStore/shared_uploads/pawansharma2045@gmail.com/sales_info.csv\")\n",
    "df2.write.saveAsTable(\"Sales1\")\n",
    "\n",
    "df3 = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"dbfs:/FileStore/shared_uploads/pawansharma2045@gmail.com/sales_info1.csv\")\n",
    "df3.write.saveAsTable(\"Sales2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f4eca3f-b5d3-488f-b4a9-45718f8097e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- employee_id: string (nullable = true)\n |-- employee_name: string (nullable = true)\n |-- salary: string (nullable = true)\n |-- department: string (nullable = true)\n\nroot\n |-- employee_id: string (nullable = true)\n |-- product_name: string (nullable = true)\n |-- product_type: string (nullable = true)\n |-- sales_count: string (nullable = true)\n |-- sales_price: string (nullable = true)\n\nroot\n |-- employee_id: string (nullable = true)\n |-- product_name: string (nullable = true)\n |-- product_type: string (nullable = true)\n |-- sales_count: string (nullable = true)\n |-- sales_price: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "#Print the dataframe schema (column and data type)\n",
    "\n",
    "df1.printSchema()\n",
    "df2.printSchema()\n",
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c3b1e07-5237-4af0-8f5b-3ab1b9bb2d08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---------+-------------------------+\n|employee_id|employee_name|salary   |department               |\n+-----------+-------------+---------+-------------------------+\n|101        |ALAX         |500000.00|CONSUMER_SALES           |\n|102        |TOM          |500000.00|CONSUMER_SALES           |\n|103        |JIM          |600000.00|CONSUMER_SALES           |\n|104        |MARK         |500000.00|CONSUMER_SALES           |\n|105        |TOMI         |700000.00|ELETRONIC_SALES          |\n|106        |AMALI        |800000.00|CONSUMER_SALES           |\n|107        |ROY          |900000.00|CONSUMER_SALES           |\n|108        |FILIP        |300000.00|AGRICULTURE_PORDUCT_SALES|\n|109        |MONNA        |800000.00|CONSUMER_SALES           |\n|110        |RONME        |500000.00|ELETRONIC_SALES          |\n|111        |SAMULE       |500000.00|AGRICULTURE_PORDUCT_SALES|\n|112        |TOD          |900000.00|AGRICULTURE_PORDUCT_SALES|\n|113        |MILI         |500000.00|ELETRONIC_SALES          |\n|114        |KIM          |900000.00|AGRICULTURE_PORDUCT_SALES|\n|115        |SESELIA      |400000.00|ELETRONIC_SALES          |\n|116        |BRIGHT       |300000.00|ELETRONIC_SALES          |\n|117        |KEN          |700000.00|AGRICULTURE_PORDUCT_SALES|\n|118        |NATALI       |900000.00|ELETRONIC_SALES          |\n+-----------+-------------+---------+-------------------------+\n\n+-----------+-------------------+------------+-----------+-----------+\n|employee_id|product_name       |product_type|sales_count|sales_price|\n+-----------+-------------------+------------+-----------+-----------+\n|101        |MANGO              |Food        |300        |400.50     |\n|101        |BANANA             |Food        |300        |200.60     |\n|102        |MANGO              |Food        |350        |400.50     |\n|103        |ORANGE             |Food        |500        |350.67     |\n|104        |GRAPE              |Food        |700        |800.45     |\n|103        |MANGO              |Food        |500        |400.50     |\n|105        |SMART TV           |ELETRONIC   |5          |50000      |\n|105        |MOBILE             |ELETRONIC   |8          |60000      |\n|113        |RICE COOKER        |ELETRONIC   |5          |4000       |\n|112        |RICE SEED 10 KG BAG|AGRICULTURE |30         |2000       |\n+-----------+-------------------+------------+-----------+-----------+\n\n+-----------+-------------------+------------+-----------+-----------+\n|employee_id|product_name       |product_type|sales_count|sales_price|\n+-----------+-------------------+------------+-----------+-----------+\n|101        |MANGO              |Food        |300        |400.50     |\n|101        |BANANA             |Food        |300        |200.60     |\n|102        |MANGO              |Food        |350        |400.50     |\n|103        |ORANGE             |Food        |500        |350.67     |\n|104        |GRAPE              |Food        |700        |800.45     |\n|103        |MANGO              |Food        |500        |400.50     |\n|105        |SMART TV           |ELETRONIC   |5          |50000      |\n|105        |MOBILE             |ELETRONIC   |8          |60000      |\n|113        |RICE COOKER        |ELETRONIC   |5          |4000       |\n|112        |RICE SEED 10 KG BAG|AGRICULTURE |30         |2000       |\n+-----------+-------------------+------------+-----------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Retrieve Information from table Employee, Sales1, Sales2\n",
    "\n",
    "spark.sql(\"select * from Employees\").show(truncate=False)\n",
    "spark.sql(\"select * from Sales1\").show(truncate=False)\n",
    "spark.sql(\"select * from Sales2\").show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01d1bbd0-742f-4c0e-b406-b4dcd240ab54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+----------------------------------------------------+-------+\n|col_name                    |data_type                                           |comment|\n+----------------------------+----------------------------------------------------+-------+\n|employee_id                 |string                                              |null   |\n|employee_name               |string                                              |null   |\n|salary                      |string                                              |null   |\n|department                  |string                                              |null   |\n|                            |                                                    |       |\n|# Detailed Table Information|                                                    |       |\n|Catalog                     |spark_catalog                                       |       |\n|Database                    |spark_example                                       |       |\n|Table                       |Employees                                           |       |\n|Created Time                |Mon May 27 02:40:09 UTC 2024                        |       |\n|Last Access                 |UNKNOWN                                             |       |\n|Created By                  |Spark 3.3.2                                         |       |\n|Statistics                  |1794 bytes                                          |       |\n|Type                        |MANAGED                                             |       |\n|Location                    |dbfs:/user/hive/warehouse/spark_example.db/employees|       |\n|Provider                    |delta                                               |       |\n|Owner                       |root                                                |       |\n|Is_managed_location         |true                                                |       |\n|Table Properties            |[delta.minReaderVersion=1,delta.minWriterVersion=2] |       |\n+----------------------------+----------------------------------------------------+-------+\n\n+----------------------------+---------------------------------------------------+-------+\n|col_name                    |data_type                                          |comment|\n+----------------------------+---------------------------------------------------+-------+\n|employee_id                 |string                                             |null   |\n|product_name                |string                                             |null   |\n|product_type                |string                                             |null   |\n|sales_count                 |string                                             |null   |\n|sales_price                 |string                                             |null   |\n|                            |                                                   |       |\n|# Detailed Table Information|                                                   |       |\n|Catalog                     |spark_catalog                                      |       |\n|Database                    |spark_example                                      |       |\n|Table                       |Sales1                                             |       |\n|Created Time                |Mon May 27 02:40:15 UTC 2024                       |       |\n|Last Access                 |UNKNOWN                                            |       |\n|Created By                  |Spark 3.3.2                                        |       |\n|Statistics                  |2029 bytes                                         |       |\n|Type                        |MANAGED                                            |       |\n|Location                    |dbfs:/user/hive/warehouse/spark_example.db/sales1  |       |\n|Provider                    |delta                                              |       |\n|Owner                       |root                                               |       |\n|Is_managed_location         |true                                               |       |\n|Table Properties            |[delta.minReaderVersion=1,delta.minWriterVersion=2]|       |\n+----------------------------+---------------------------------------------------+-------+\n\n+----------------------------+---------------------------------------------------+-------+\n|col_name                    |data_type                                          |comment|\n+----------------------------+---------------------------------------------------+-------+\n|employee_id                 |string                                             |null   |\n|product_name                |string                                             |null   |\n|product_type                |string                                             |null   |\n|sales_count                 |string                                             |null   |\n|sales_price                 |string                                             |null   |\n|                            |                                                   |       |\n|# Detailed Table Information|                                                   |       |\n|Catalog                     |spark_catalog                                      |       |\n|Database                    |spark_example                                      |       |\n|Table                       |Sales2                                             |       |\n|Created Time                |Mon May 27 02:40:23 UTC 2024                       |       |\n|Last Access                 |UNKNOWN                                            |       |\n|Created By                  |Spark 3.3.2                                        |       |\n|Statistics                  |2029 bytes                                         |       |\n|Type                        |MANAGED                                            |       |\n|Location                    |dbfs:/user/hive/warehouse/spark_example.db/sales2  |       |\n|Provider                    |delta                                              |       |\n|Owner                       |root                                               |       |\n|Is_managed_location         |true                                               |       |\n|Table Properties            |[delta.minReaderVersion=1,delta.minWriterVersion=2]|       |\n+----------------------------+---------------------------------------------------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "#Show \n",
    "spark.sql(\"DESCRIBE FORMATTED Employees\").show(truncate=False)\n",
    "spark.sql(\"DESCRIBE FORMATTED Sales1\").show(truncate=False)\n",
    "spark.sql(\"DESCRIBE FORMATTED Sales2\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb584133-0e12-43c6-b1de-261edde76ab9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---------+-------------------------+\n|employee_id|employee_name|salary   |department               |\n+-----------+-------------+---------+-------------------------+\n|101        |ALAX         |500000.00|CONSUMER_SALES           |\n|102        |TOM          |500000.00|CONSUMER_SALES           |\n|103        |JIM          |600000.00|CONSUMER_SALES           |\n|104        |MARK         |500000.00|CONSUMER_SALES           |\n|105        |TOMI         |700000.00|ELETRONIC_SALES          |\n|106        |AMALI        |800000.00|CONSUMER_SALES           |\n|107        |ROY          |900000.00|CONSUMER_SALES           |\n|108        |FILIP        |300000.00|AGRICULTURE_PORDUCT_SALES|\n|109        |MONNA        |800000.00|CONSUMER_SALES           |\n|110        |RONME        |500000.00|ELETRONIC_SALES          |\n|111        |SAMULE       |500000.00|AGRICULTURE_PORDUCT_SALES|\n|112        |TOD          |900000.00|AGRICULTURE_PORDUCT_SALES|\n|113        |MILI         |500000.00|ELETRONIC_SALES          |\n|114        |KIM          |900000.00|AGRICULTURE_PORDUCT_SALES|\n|115        |SESELIA      |400000.00|ELETRONIC_SALES          |\n|116        |BRIGHT       |300000.00|ELETRONIC_SALES          |\n|117        |KEN          |700000.00|AGRICULTURE_PORDUCT_SALES|\n|118        |NATALI       |900000.00|ELETRONIC_SALES          |\n+-----------+-------------+---------+-------------------------+\n\nroot\n |-- employee_id: string (nullable = true)\n |-- employee_name: string (nullable = true)\n |-- salary: string (nullable = true)\n |-- department: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "#Import spark sql types \n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "\n",
    "#Create spark schema by StructType and StructField\n",
    "\n",
    "employees_info = StructType([\n",
    "    StructField('employee_id', IntegerType(), True),\n",
    "    StructField('employee_name', StringType(), True),\n",
    "    StructField('salary', DoubleType(), True),\n",
    "    StructField('department', StringType(), True)\n",
    "])\n",
    "\n",
    "#Load data from CSV to Spark Dataframe\n",
    "employees_info = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"dbfs:/FileStore/shared_uploads/pawansharma2045@gmail.com/employees.csv\")\n",
    "\n",
    "#Check and Show dataframe data by .show() method\n",
    "employees_info.show(20, truncate=False)\n",
    "\n",
    "#Print The schema of dataframe by .printSchema()\n",
    "employees_info.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79beffc4-3626-4245-8ae4-3be15dbbdae4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+------------+-----------+-----------+\n|employee_id|product_name       |product_type|sales_count|sales_price|\n+-----------+-------------------+------------+-----------+-----------+\n|101        |MANGO              |Food        |300        |400.50     |\n|101        |BANANA             |Food        |300        |200.60     |\n|102        |MANGO              |Food        |350        |400.50     |\n|103        |ORANGE             |Food        |500        |350.67     |\n|104        |GRAPE              |Food        |700        |800.45     |\n|103        |MANGO              |Food        |500        |400.50     |\n|105        |SMART TV           |ELETRONIC   |5          |50000      |\n|105        |MOBILE             |ELETRONIC   |8          |60000      |\n|113        |RICE COOKER        |ELETRONIC   |5          |4000       |\n|112        |RICE SEED 10 KG BAG|AGRICULTURE |30         |2000       |\n+-----------+-------------------+------------+-----------+-----------+\n\nroot\n |-- employee_id: string (nullable = true)\n |-- product_name: string (nullable = true)\n |-- product_type: string (nullable = true)\n |-- sales_count: string (nullable = true)\n |-- sales_price: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "sales1_info = StructType([\\\n",
    "    StructField('employee_id', IntegerType(), True),\\\n",
    "    StructField('product_name', StringType(), True),\\\n",
    "    StructField('product_type', StringType(), True),\\\n",
    "    StructField('sales_count', IntegerType(), True),\\\n",
    "    StructField('sales_price', DoubleType(), True)\\\n",
    "  ])\n",
    "  \n",
    "sales1_info = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"dbfs:/FileStore/shared_uploads/pawansharma2045@gmail.com/sales_info.csv\")\n",
    "sales1_info.show(20, truncate=False)\n",
    "sales1_info.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3abc0c5e-6406-400c-be8e-545ab3ed1298",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+------------+-----------+-----------+\n|employee_id|product_name       |product_type|sales_count|sales_price|\n+-----------+-------------------+------------+-----------+-----------+\n|101        |MANGO              |Food        |300        |400.50     |\n|101        |BANANA             |Food        |300        |200.60     |\n|102        |MANGO              |Food        |350        |400.50     |\n|103        |ORANGE             |Food        |500        |350.67     |\n|104        |GRAPE              |Food        |700        |800.45     |\n|103        |MANGO              |Food        |500        |400.50     |\n|105        |SMART TV           |ELETRONIC   |5          |50000      |\n|105        |MOBILE             |ELETRONIC   |8          |60000      |\n|113        |RICE COOKER        |ELETRONIC   |5          |4000       |\n|112        |RICE SEED 10 KG BAG|AGRICULTURE |30         |2000       |\n+-----------+-------------------+------------+-----------+-----------+\n\nroot\n |-- employee_id: string (nullable = true)\n |-- product_name: string (nullable = true)\n |-- product_type: string (nullable = true)\n |-- sales_count: string (nullable = true)\n |-- sales_price: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "sales2_info = StructType([\\\n",
    "    StructField('employee_id', IntegerType(), True),\\\n",
    "    StructField('product_name', StringType(), True),\\\n",
    "    StructField('product_type', StringType(), True),\\\n",
    "    StructField('sales_count', IntegerType(), True),\\\n",
    "    StructField('sales_price', DoubleType(), True)\\\n",
    "  ])\n",
    "sales2_info = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"dbfs:/FileStore/shared_uploads/pawansharma2045@gmail.com/sales_info1.csv\")\n",
    "sales2_info.show(20, truncate=False)\n",
    "sales2_info.printSchema()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Spark SQL queries on Hive Table",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
